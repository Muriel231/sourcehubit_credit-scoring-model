{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff2add1-8a92-4c5f-824a-3729b95f3d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4356df-5ee1-4613-9823-8892fb6e7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, skipping the first row and assigning column names manually\n",
    "df = pd.read_csv(r\"C:\\Users\\Chrizel\\Documents\\Copy of default of credit card clients.csv\", header=None, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f7d47d-1825-4dd5-bd24-21bafedc2516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\n",
    "    \"ID\", \"LIMIT_BAL\", \"SEX\", \"EDUCATION\", \"MARRIAGE\", \"AGE\",\n",
    "    \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\",\n",
    "    \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\",\n",
    "    \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\",\n",
    "    \"default payment next month\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341e732a-278d-4c36-b197-74e964cd7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to numeric, coerce errors to NaN\n",
    "df = df.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f8e837-b300-4f33-9377-20e3c1a0df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
      "0  NaN        NaN  NaN        NaN       NaN   NaN    NaN    NaN    NaN    NaN   \n",
      "1  1.0    20000.0  2.0        2.0       1.0  24.0    2.0    2.0   -1.0   -1.0   \n",
      "2  2.0   120000.0  2.0        2.0       2.0  26.0   -1.0    2.0    0.0    0.0   \n",
      "3  3.0    90000.0  2.0        2.0       2.0  34.0    0.0    0.0    0.0    0.0   \n",
      "4  4.0    50000.0  2.0        2.0       1.0  37.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "0  ...        NaN        NaN        NaN       NaN       NaN       NaN   \n",
      "1  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
      "2  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
      "3  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
      "4  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
      "\n",
      "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
      "0       NaN       NaN       NaN                         NaN  \n",
      "1       0.0       0.0       0.0                         1.0  \n",
      "2    1000.0       0.0    2000.0                         1.0  \n",
      "3    1000.0    1000.0    5000.0                         0.0  \n",
      "4    1100.0    1069.0    1000.0                         0.0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "ID                            float64\n",
      "LIMIT_BAL                     float64\n",
      "SEX                           float64\n",
      "EDUCATION                     float64\n",
      "MARRIAGE                      float64\n",
      "AGE                           float64\n",
      "PAY_0                         float64\n",
      "PAY_2                         float64\n",
      "PAY_3                         float64\n",
      "PAY_4                         float64\n",
      "PAY_5                         float64\n",
      "PAY_6                         float64\n",
      "BILL_AMT1                     float64\n",
      "BILL_AMT2                     float64\n",
      "BILL_AMT3                     float64\n",
      "BILL_AMT4                     float64\n",
      "BILL_AMT5                     float64\n",
      "BILL_AMT6                     float64\n",
      "PAY_AMT1                      float64\n",
      "PAY_AMT2                      float64\n",
      "PAY_AMT3                      float64\n",
      "PAY_AMT4                      float64\n",
      "PAY_AMT5                      float64\n",
      "PAY_AMT6                      float64\n",
      "default payment next month    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows, data types, and missing value count\n",
    "print(df.head())\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aaf4352a-68b3-42b2-86d7-76dab8972068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                            1\n",
      "LIMIT_BAL                     1\n",
      "SEX                           1\n",
      "EDUCATION                     1\n",
      "MARRIAGE                      1\n",
      "AGE                           1\n",
      "PAY_0                         1\n",
      "PAY_2                         1\n",
      "PAY_3                         1\n",
      "PAY_4                         1\n",
      "PAY_5                         1\n",
      "PAY_6                         1\n",
      "BILL_AMT1                     1\n",
      "BILL_AMT2                     1\n",
      "BILL_AMT3                     1\n",
      "BILL_AMT4                     1\n",
      "BILL_AMT5                     1\n",
      "BILL_AMT6                     1\n",
      "PAY_AMT1                      1\n",
      "PAY_AMT2                      1\n",
      "PAY_AMT3                      1\n",
      "PAY_AMT4                      1\n",
      "PAY_AMT5                      1\n",
      "PAY_AMT6                      1\n",
      "default payment next month    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())  \n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "983f654d-65fa-46d9-a1e4-477a4c093184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop(columns=[\"ID\", \"default payment next month\"])\n",
    "y = df[\"default payment next month\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "645c5b6e-1dbd-4745-8b23-16466367f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split to split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f56b47d3-1c2e-403f-9641-ceb452c5cbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8100\n",
      "Precision: 0.6927\n",
      "Recall: 0.2369\n"
     ]
    }
   ],
   "source": [
    "# Import necessary tools for scaling and logistic regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train model with scaled data\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c871bcbd-69b0-4c0d-8160-3f630678f7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8160\n",
      "Random Forest Precision: 0.6380\n",
      "Random Forest Recall: 0.3679\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Train on scaled data (or you can use unscaled, RF works fine without scaling)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"Random Forest Precision: {precision_rf:.4f}\")\n",
    "print(f\"Random Forest Recall: {recall_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b71b1-1d75-40e2-8604-b80b087cb756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60ac1fde-c054-44d9-a887-874a87c11473",
   "metadata": {},
   "source": [
    "# Credit Scoring Model - Internship Task Report\n",
    "\n",
    "## Objective\n",
    "Build a machine learning model to predict a personâ€™s creditworthiness using historical financial data. The goal is to classify whether a client will default on their credit card payment next month.\n",
    "\n",
    "\n",
    "\n",
    "##  Dataset\n",
    "The dataset contains 30,001 records of credit card clients with features such as:\n",
    "\n",
    "- `LIMIT_BAL`: Credit limit  \n",
    "- `SEX`, `EDUCATION`, `MARRIAGE`, `AGE`: Demographic info  \n",
    "- `PAY_0` to `PAY_6`: Payment status history  \n",
    "- `BILL_AMT1` to `BILL_AMT6`: Bill statement amounts  \n",
    "- `PAY_AMT1` to `PAY_AMT6`: Payment amounts  \n",
    "- `default payment next month`: Target variable (0 = no default, 1 = default)\n",
    "\n",
    "\n",
    "\n",
    "##  Data Preprocessing\n",
    "- Loaded the data and assigned column names  \n",
    "- Converted all features to numeric and dropped missing values  \n",
    "- Split data into features (`X`) and target (`y`)  \n",
    "- Applied train-test split (80% training, 20% testing)  \n",
    "- Used `StandardScaler` for feature scaling (required for Logistic Regression)\n",
    "\n",
    "\n",
    "\n",
    "##  Models Used\n",
    "- **Logistic Regression**  \n",
    "- **Random Forest Classifier**\n",
    "\n",
    "\n",
    "\n",
    "## Evaluation Metrics\n",
    "- **Accuracy**: Correct predictions out of total samples  \n",
    "- **Precision**: How many predicted defaults were actual defaults  \n",
    "- **Recall**: How many actual defaults were correctly predicted\n",
    "\n",
    "\n",
    "\n",
    "##  Results\n",
    "\n",
    "| Model               | Accuracy | Precision | Recall  |\n",
    "|---------------------|----------|-----------|---------|\n",
    "| Logistic Regression | 0.8100   | 0.6927    | 0.2369  |\n",
    "| Random Forest       | 0.8160   | 0.6380    | 0.3679  |\n",
    "\n",
    "\n",
    "\n",
    "##  Analysis\n",
    "- Random Forest performed slightly better in both accuracy and recall  \n",
    "- Logistic Regression had slightly better precision  \n",
    "- Random Forest is more effective for identifying defaulters (better recall)\n",
    "\n",
    "\n",
    "\n",
    "##  Conclusion\n",
    "The task was successfully completed using Python, pandas, and scikit-learn.  \n",
    "Both models were trained and evaluated. Random Forest showed better performance in catching defaulters, which is critical in credit risk assessment.  \n",
    "Further improvements could include hyperparameter tuning and feature engineering.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
